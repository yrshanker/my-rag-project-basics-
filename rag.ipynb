{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98df19ab",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a858f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 150 entries\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "with open('/Users/yashrajshanker/Desktop/Projects/RAG/demo_simple_rag_py/cat-facts.txt', 'r') as file:\n",
    "  dataset = file.readlines()\n",
    "  print(f'Loaded {len(dataset)} entries')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a247590a",
   "metadata": {},
   "source": [
    "### Implementing the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3252921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "EMBEDDING_MODEL = 'hf.co/CompendiumLabs/bge-base-en-v1.5-gguf'\n",
    "LANGUAGE_MODEL = 'hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF'\n",
    "\n",
    "# Each element in the VECTOR_DB will be a tuple (chunk, embedding)\n",
    "# The embedding is a list of floats, for example: [0.1, 0.04, -0.34, 0.21, ...]\n",
    "VECTOR_DB = []\n",
    "\n",
    "def add_chunk_to_database(chunk):\n",
    "  embedding = ollama.embed(model=EMBEDDING_MODEL, input=chunk)['embeddings'][0]\n",
    "  VECTOR_DB.append((chunk, embedding))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32218ff6",
   "metadata": {},
   "source": [
    "### Each line in the dataset is considered as a chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "945dd4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added chunk 1/150 to the database\n",
      "Added chunk 2/150 to the database\n",
      "Added chunk 3/150 to the database\n",
      "Added chunk 4/150 to the database\n",
      "Added chunk 5/150 to the database\n",
      "Added chunk 6/150 to the database\n",
      "Added chunk 7/150 to the database\n",
      "Added chunk 8/150 to the database\n",
      "Added chunk 9/150 to the database\n",
      "Added chunk 10/150 to the database\n",
      "Added chunk 11/150 to the database\n",
      "Added chunk 12/150 to the database\n",
      "Added chunk 13/150 to the database\n",
      "Added chunk 14/150 to the database\n",
      "Added chunk 15/150 to the database\n",
      "Added chunk 16/150 to the database\n",
      "Added chunk 17/150 to the database\n",
      "Added chunk 18/150 to the database\n",
      "Added chunk 19/150 to the database\n",
      "Added chunk 20/150 to the database\n",
      "Added chunk 21/150 to the database\n",
      "Added chunk 22/150 to the database\n",
      "Added chunk 23/150 to the database\n",
      "Added chunk 24/150 to the database\n",
      "Added chunk 25/150 to the database\n",
      "Added chunk 26/150 to the database\n",
      "Added chunk 27/150 to the database\n",
      "Added chunk 28/150 to the database\n",
      "Added chunk 29/150 to the database\n",
      "Added chunk 30/150 to the database\n",
      "Added chunk 31/150 to the database\n",
      "Added chunk 32/150 to the database\n",
      "Added chunk 33/150 to the database\n",
      "Added chunk 34/150 to the database\n",
      "Added chunk 35/150 to the database\n",
      "Added chunk 36/150 to the database\n",
      "Added chunk 37/150 to the database\n",
      "Added chunk 38/150 to the database\n",
      "Added chunk 39/150 to the database\n",
      "Added chunk 40/150 to the database\n",
      "Added chunk 41/150 to the database\n",
      "Added chunk 42/150 to the database\n",
      "Added chunk 43/150 to the database\n",
      "Added chunk 44/150 to the database\n",
      "Added chunk 45/150 to the database\n",
      "Added chunk 46/150 to the database\n",
      "Added chunk 47/150 to the database\n",
      "Added chunk 48/150 to the database\n",
      "Added chunk 49/150 to the database\n",
      "Added chunk 50/150 to the database\n",
      "Added chunk 51/150 to the database\n",
      "Added chunk 52/150 to the database\n",
      "Added chunk 53/150 to the database\n",
      "Added chunk 54/150 to the database\n",
      "Added chunk 55/150 to the database\n",
      "Added chunk 56/150 to the database\n",
      "Added chunk 57/150 to the database\n",
      "Added chunk 58/150 to the database\n",
      "Added chunk 59/150 to the database\n",
      "Added chunk 60/150 to the database\n",
      "Added chunk 61/150 to the database\n",
      "Added chunk 62/150 to the database\n",
      "Added chunk 63/150 to the database\n",
      "Added chunk 64/150 to the database\n",
      "Added chunk 65/150 to the database\n",
      "Added chunk 66/150 to the database\n",
      "Added chunk 67/150 to the database\n",
      "Added chunk 68/150 to the database\n",
      "Added chunk 69/150 to the database\n",
      "Added chunk 70/150 to the database\n",
      "Added chunk 71/150 to the database\n",
      "Added chunk 72/150 to the database\n",
      "Added chunk 73/150 to the database\n",
      "Added chunk 74/150 to the database\n",
      "Added chunk 75/150 to the database\n",
      "Added chunk 76/150 to the database\n",
      "Added chunk 77/150 to the database\n",
      "Added chunk 78/150 to the database\n",
      "Added chunk 79/150 to the database\n",
      "Added chunk 80/150 to the database\n",
      "Added chunk 81/150 to the database\n",
      "Added chunk 82/150 to the database\n",
      "Added chunk 83/150 to the database\n",
      "Added chunk 84/150 to the database\n",
      "Added chunk 85/150 to the database\n",
      "Added chunk 86/150 to the database\n",
      "Added chunk 87/150 to the database\n",
      "Added chunk 88/150 to the database\n",
      "Added chunk 89/150 to the database\n",
      "Added chunk 90/150 to the database\n",
      "Added chunk 91/150 to the database\n",
      "Added chunk 92/150 to the database\n",
      "Added chunk 93/150 to the database\n",
      "Added chunk 94/150 to the database\n",
      "Added chunk 95/150 to the database\n",
      "Added chunk 96/150 to the database\n",
      "Added chunk 97/150 to the database\n",
      "Added chunk 98/150 to the database\n",
      "Added chunk 99/150 to the database\n",
      "Added chunk 100/150 to the database\n",
      "Added chunk 101/150 to the database\n",
      "Added chunk 102/150 to the database\n",
      "Added chunk 103/150 to the database\n",
      "Added chunk 104/150 to the database\n",
      "Added chunk 105/150 to the database\n",
      "Added chunk 106/150 to the database\n",
      "Added chunk 107/150 to the database\n",
      "Added chunk 108/150 to the database\n",
      "Added chunk 109/150 to the database\n",
      "Added chunk 110/150 to the database\n",
      "Added chunk 111/150 to the database\n",
      "Added chunk 112/150 to the database\n",
      "Added chunk 113/150 to the database\n",
      "Added chunk 114/150 to the database\n",
      "Added chunk 115/150 to the database\n",
      "Added chunk 116/150 to the database\n",
      "Added chunk 117/150 to the database\n",
      "Added chunk 118/150 to the database\n",
      "Added chunk 119/150 to the database\n",
      "Added chunk 120/150 to the database\n",
      "Added chunk 121/150 to the database\n",
      "Added chunk 122/150 to the database\n",
      "Added chunk 123/150 to the database\n",
      "Added chunk 124/150 to the database\n",
      "Added chunk 125/150 to the database\n",
      "Added chunk 126/150 to the database\n",
      "Added chunk 127/150 to the database\n",
      "Added chunk 128/150 to the database\n",
      "Added chunk 129/150 to the database\n",
      "Added chunk 130/150 to the database\n",
      "Added chunk 131/150 to the database\n",
      "Added chunk 132/150 to the database\n",
      "Added chunk 133/150 to the database\n",
      "Added chunk 134/150 to the database\n",
      "Added chunk 135/150 to the database\n",
      "Added chunk 136/150 to the database\n",
      "Added chunk 137/150 to the database\n",
      "Added chunk 138/150 to the database\n",
      "Added chunk 139/150 to the database\n",
      "Added chunk 140/150 to the database\n",
      "Added chunk 141/150 to the database\n",
      "Added chunk 142/150 to the database\n",
      "Added chunk 143/150 to the database\n",
      "Added chunk 144/150 to the database\n",
      "Added chunk 145/150 to the database\n",
      "Added chunk 146/150 to the database\n",
      "Added chunk 147/150 to the database\n",
      "Added chunk 148/150 to the database\n",
      "Added chunk 149/150 to the database\n",
      "Added chunk 150/150 to the database\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(dataset):\n",
    "  add_chunk_to_database(chunk)\n",
    "  print(f'Added chunk {i+1}/{len(dataset)} to the database')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb07206",
   "metadata": {},
   "source": [
    "### Retriever Function\n",
    "\n",
    "#### Cosine Similarity: The higher the similarity score, the closer are the chunks in meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe10fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "  dot_product = sum([x * y for x, y in zip(a, b)])\n",
    "  norm_a = sum([x ** 2 for x in a]) ** 0.5\n",
    "  norm_b = sum([x ** 2 for x in b]) ** 0.5\n",
    "  return dot_product / (norm_a * norm_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ffc2f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b884bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, top_n=3):\n",
    "  query_embedding = ollama.embed(model=EMBEDDING_MODEL, input=query)['embeddings'][0]\n",
    "  # temporary list to store (chunk, similarity) pairs\n",
    "  similarities = []\n",
    "  for chunk, embedding in VECTOR_DB:\n",
    "    similarity = cosine_similarity(query_embedding, embedding)\n",
    "    similarities.append((chunk, similarity))\n",
    "  # sort by similarity in descending order, because higher similarity means more relevant chunks\n",
    "  similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "  # finally, return the top N most relevant chunks\n",
    "  return similarities[:top_n]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336f2c5",
   "metadata": {},
   "source": [
    "### Generation Phase: Chatbot generates a response based on the rerived knowledge from the Step above  \n",
    "#### This is done by simply add the chunks into the prompt that will be taken as input for the chatbot  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34867e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved knowledge:\n",
      " - (similarity: 0.89) When well treated, a cat can live twenty or more years but the average life span of a domestic cat is 14 years.\n",
      "\n",
      " - (similarity: 0.82) The oldest cat on record was Crème Puff from Austin, Texas, who lived from 1967 to August 6, 2005, three days after her 38th birthday. A cat typically can live up to 20 years, which is equivalent to about 96 human years.\n",
      "\n",
      " - (similarity: 0.75) On average, cats spend 2/3 of every day sleeping. That means a nine-year-old cat has been awake for only three years of its life.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_query = input('Ask me a question: ')\n",
    "retrieved_knowledge = retrieve(input_query)\n",
    "\n",
    "print('Retrieved knowledge:')\n",
    "for chunk, similarity in retrieved_knowledge:\n",
    "  print(f' - (similarity: {similarity:.2f}) {chunk}')\n",
    "\n",
    "instruction_prompt = f'''You are a helpful chatbot.\n",
    "Use only the following pieces of context to answer the question. Don't make up any new information:\n",
    "{'\\n'.join([f' - {chunk}' for chunk, similarity in retrieved_knowledge])}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b59adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot response:\n",
      "A domestic cat typically lives up to 14 years on average. However, some cats have lived longer than others."
     ]
    }
   ],
   "source": [
    "stream = ollama.chat(\n",
    "  model=LANGUAGE_MODEL,\n",
    "  messages=[\n",
    "    {'role': 'system', 'content': instruction_prompt},\n",
    "    {'role': 'user', 'content': input_query},\n",
    "  ],\n",
    "  stream=True,\n",
    ")\n",
    "\n",
    "# print the response from the chatbot in real-time\n",
    "print('Chatbot response:')\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded7eaa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenCV-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
